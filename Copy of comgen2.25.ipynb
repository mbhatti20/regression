{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"comgen2.25.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tNxDp3Me4zXx","colab_type":"text"},"source":["\n","# NMT-Keras tutorial\n","---\n","\n","This notebook describes, step by step, how to build a neural machine translation model with NMT-Keras. The tutorial is organized in different sections:\n","\n","\n","1. Create a Dataset instance, in order to properly manage the data. \n","2. Create and train the Neural Translation Model in the training data.\n","3. Apply the trained model on new (unseen) data.\n","\n","All these steps are automatically run by the toolkit. But, to learn and understand the full process, it is didactic to follow this tutorial.\n","\n","\n","So, let's start installing the toolkit."]},{"cell_type":"code","metadata":{"id":"n6RpYGOpibK5","colab_type":"code","colab":{}},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-4NRRCudCCsR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":955},"executionInfo":{"status":"ok","timestamp":1597292675177,"user_tz":420,"elapsed":4510,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"0e77b1e2-4f44-45e9-8d03-2092200a19bf"},"source":["!cat /proc/cpuinfo"],"execution_count":null,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SkEbqEWb8uAP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1597292676038,"user_tz":420,"elapsed":5360,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"581335dc-7901-4ac0-9b37-5ad0745c9658"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thu Aug 13 04:24:35 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   57C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"egprMcTp8fLC","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Pkl6pHqucCk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597292676192,"user_tz":420,"elapsed":5496,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"5019d8b0-12d4-4f8f-b623-be89d07ad188"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iS14LJ_N8hGW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597292677237,"user_tz":420,"elapsed":6531,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"5798e648-efa5-4f47-a4cf-f28d4158371c"},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jcuhzRGV8q56","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597292677522,"user_tz":420,"elapsed":6805,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"6876bdf2-18bd-4ec5-c909-0f5c236b10e8"},"source":["from sklearn.model_selection import train_test_split\n","import csv\n","import sys\n","import os\n","csv.field_size_limit(sys.maxsize)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["131072"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"0mtJWLes5JO7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597292697665,"user_tz":420,"elapsed":26938,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"f8910e17-2d15-4831-ab15-146257c98d7f"},"source":["os.chdir(\"drive/My Drive/Coding stuff\")\n","!pip install update pip\n","!pip uninstall -y keras  # Avoid crashes with pre-installed packages\n","!git clone https://github.com/lvapeab/nmt-keras\n","os.chdir('nmt-keras')\n","!pip install -e ."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: update in /usr/local/lib/python3.6/dist-packages (0.0.1)\n","Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n","Requirement already satisfied: style==1.1.0 in /usr/local/lib/python3.6/dist-packages (from update) (1.1.0)\n","Uninstalling Keras-2.4.3:\n","  Successfully uninstalled Keras-2.4.3\n","Obtaining file:///content/drive/My%20Drive/Coding%20stuff/nmt-keras\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (0.16.0)\n","Collecting keras@ https://github.com/MarcBS/keras/archive/master.zip\n","\u001b[?25l  Downloading https://github.com/MarcBS/keras/archive/master.zip\n","\u001b[K     / 120.6MB 54kB/s\n","\u001b[?25hRequirement already satisfied: keras_applications in /tensorflow-1.15.2/python3.6 (from nmt-keras==0.6) (1.0.8)\n","Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (1.1.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (2.10.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (3.2.2)\n","Requirement already satisfied: multimodal-keras-wrapper in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (1.18.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (0.16.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (0.22.2.post1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (1.15.0)\n","Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (3.4.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (1.0.5)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (1.4.13)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (0.0.43)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nmt-keras==0.6) (1.4.1)\n","Requirement already satisfied: tensorflow<2 in /tensorflow-1.15.2/python3.6 (from nmt-keras==0.6) (1.15.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras@ https://github.com/MarcBS/keras/archive/master.zip->nmt-keras==0.6) (3.13)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nmt-keras==0.6) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nmt-keras==0.6) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nmt-keras==0.6) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nmt-keras==0.6) (2.4.7)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from multimodal-keras-wrapper->nmt-keras==0.6) (0.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from multimodal-keras-wrapper->nmt-keras==0.6) (0.29.21)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from multimodal-keras-wrapper->nmt-keras==0.6) (0.10.0)\n","Requirement already satisfied: subword-nmt in /usr/local/lib/python3.6/dist-packages (from multimodal-keras-wrapper->nmt-keras==0.6) (0.3.7)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->nmt-keras==0.6) (2.4.1)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->nmt-keras==0.6) (7.0.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->nmt-keras==0.6) (2.4)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->nmt-keras==0.6) (1.1.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nmt-keras==0.6) (0.16.0)\n","Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->nmt-keras==0.6) (2.7.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nmt-keras==0.6) (2018.9)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu->nmt-keras==0.6) (2.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses->nmt-keras==0.6) (4.41.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->nmt-keras==0.6) (7.1.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses->nmt-keras==0.6) (2019.12.20)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (0.8.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (0.2.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (3.12.4)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.6 (from tensorflow<2->nmt-keras==0.6) (1.15.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (0.2.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (1.31.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (3.3.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (0.34.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (0.9.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.6 (from tensorflow<2->nmt-keras==0.6) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2->nmt-keras==0.6) (1.12.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->nmt-keras==0.6) (4.4.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2->nmt-keras==0.6) (49.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (3.1.0)\n","Building wheels for collected packages: keras\n","  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras: filename=Keras-2.3.1.1-cp36-none-any.whl size=487500 sha256=282e5701d56d3d135c65ade8c43e4973cf32405383353ae3ae88b258c860e74f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-s6las8ci/wheels/82/f8/db/7c0c999dced9850abb60944d255a31dbdf10f76f645454b715\n","Successfully built keras\n","Installing collected packages: keras, nmt-keras\n","  Found existing installation: nmt-keras 0.6\n","    Can't uninstall 'nmt-keras'. No files were found to uninstall.\n","  Running setup.py develop for nmt-keras\n","Successfully installed keras-2.3.1.1 nmt-keras\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nKDMqb68y6cA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"ok","timestamp":1597292700985,"user_tz":420,"elapsed":30247,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"8c34025f-b963-4593-f846-bf54cddfe26c"},"source":["!pip install --upgrade wandb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: wandb in /usr/local/lib/python3.6/dist-packages (0.9.4)\n","Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n","Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.0)\n","Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n","Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n","Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied, skipping upgrade: gql==0.2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.2.0)\n","Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.16.3)\n","Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.7)\n","Requirement already satisfied, skipping upgrade: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.3)\n","Requirement already satisfied, skipping upgrade: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n","Requirement already satisfied, skipping upgrade: graphql-core<2,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (1.1)\n","Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.10)\n","Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n","Requirement already satisfied, skipping upgrade: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n","Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5a3G4cDCy84_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597292702544,"user_tz":420,"elapsed":31795,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"2eeaa404-5c96-4a9d-e3d7-069e1f523244"},"source":["#removed my wandb key here to share publicly, you should put your key after \"login\"\n","!wandb login"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"noKJ5d4rdTj6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597292704572,"user_tz":420,"elapsed":33810,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"ae9c04e8-937b-426b-8ffb-7fa8f88f8aa1"},"source":["import keras"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"IrgKeZKBcvs7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1597292711422,"user_tz":420,"elapsed":40647,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"2d3a319c-7b13-4a8e-c73b-68eec412eb47"},"source":["import wandb\n","from wandb.keras import WandbCallback\n","wandb.init(project=\"comgen\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://app.wandb.ai/dhanushp/comgen\" target=\"_blank\">https://app.wandb.ai/dhanushp/comgen</a><br/>\n","                Run page: <a href=\"https://app.wandb.ai/dhanushp/comgen/runs/1v0hmgut\" target=\"_blank\">https://app.wandb.ai/dhanushp/comgen/runs/1v0hmgut</a><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["W&B Run: https://app.wandb.ai/dhanushp/comgen/runs/1v0hmgut"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"lQIo-qo8yjF3","colab_type":"code","colab":{}},"source":["import logging\n","logger = logging.getLogger(\"wandb\")\n","logger.setLevel(logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AzHw6ks17z3R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1597292717330,"user_tz":420,"elapsed":46539,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"b321ae85-d61b-4065-c9ae-b81ea325fb20"},"source":["!python -c \"import keras; print(keras.__version__)\"\n","!python -c \"import tensorflow; print(tensorflow.__version__)\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2.3.1\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wybzPN14qA1V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597292718807,"user_tz":420,"elapsed":48007,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"f8e883bf-0e93-4cbe-c8f0-a35ce5ae077a"},"source":["import tensorflow as tf\n","tf.test.is_gpu_available()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"B6bRna4hv2XF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597292721688,"user_tz":420,"elapsed":50878,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"321beb6a-f75b-44df-8b72-c67825411450"},"source":["!pip install more-itertools"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (8.4.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VSSh7bps4y1U","colab_type":"text"},"source":["## 1. Building a Dataset model\n","First, we are creating a [Dataset](https://github.com/MarcBS/multimodal_keras_wrapper/keras_wrapper/dataset.py) object (from the [Multimodal Keras Wrapper](https://github.com/MarcBS/multimodal_keras_wrapper) library). This object will be the interface between our data (text files) and the model:"]},{"cell_type":"code","metadata":{"id":"hiY2fUFU83Rx","colab_type":"code","colab":{}},"source":["from keras_wrapper.dataset import Dataset, saveDataset\n","from data_engine.prepare_data import keep_n_captions\n","dataset = Dataset('tutorial_dataset', 'tutorial', silence=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ify05BL8_Rj","colab_type":"text"},"source":["Now that we have the empty dataset, we must indicate its inputs and outputs. In our case, we'll have two different inputs and one single output:\n","\n","1. Outputs:\n","**target_text**: Sentences in our target language.\n","\n","2. Inputs:\n","**source_text**: Sentences in the source language.\n","\n","**state_below**: Sentences in the target language, but shifted one position to the right (for teacher-forcing training of the model).\n","\n","For setting up the outputs, we use the setOutputs function, with the appropriate parameters. Note that, when we are building the dataset for the training split, we build the vocabulary (up to 30000 words)."]},{"cell_type":"code","metadata":{"id":"Y0GvUVhThnxo","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_L1RQUYA3Fs","colab_type":"code","colab":{}},"source":["coding_dir = \"/content/drive/My Drive/Coding stuff\"\n","os.chdir(coding_dir)\n","file_path_raw = \"alldata-allfields-withtypes-parens-filtered.csv\"#\"alldata-allfields-withtypes-parens.csv\"\n","file_path = \"alldata-allfields-withtypes-parens-uniques.csv\"\n","docstring_header = \"docstring\"\n","ast_header = \"ast\"\n","start_word = \"<start>\"\n","end_word = \"<end>\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5dl9l1nkXu4H","colab_type":"code","colab":{}},"source":["n_parallel_loaders = 3\n","beam_size = 6 if tf.test.is_gpu_available() else 1\n","# beam_size = 3 if tf.test.is_gpu_available() else 1\n","# tokenize_y = \"tokenize_montreal\"\n","# tokenize_x = \"tokenize_soft\"\n","batch_size = 200 #230 #72 #280 #140 #230\n","tokenize_y = \"tokenize_none\"\n","tokenize_x = \"tokenize_none\"\n","# tokenize_y = \"tokenize_soft\"\n","# tokenize_x = \"tokenize_soft\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rhh1zmMC3QUc","colab_type":"code","colab":{}},"source":["# from more_itertools import unique_everseen\n","\n","open(file_path, 'w').close()\n","# with open(file_path_raw,'r') as in_file, open(file_path,'a+') as out_file:\n","#     out_file.writelines(unique_everseen(in_file))\n","with open(file_path_raw,'r') as in_file, open(file_path,'a+') as out_file:    \n","  seen = set() # set for fast O(1) amortized lookup\n","  for line in in_file:\n","      if line in seen: continue # skip duplicate\n","      seen.add(line)\n","      out_file.write(line)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMujB69V87nB","colab_type":"code","colab":{}},"source":["import string\n","import re\n","import random\n","\n","def create_dataset(path_to_file, num_examples=None):\n","    iterations = 0\n","    docstring_data, ast_data = [], []\n","    d_lens, a_lens = [], []\n","    d_lens_filtered, a_lens_filtered = [], []\n","    print(path_to_file,num_examples)\n","    def preprocesser_d(x):\n","      x = x.replace('\\n', ' ').strip().lower()\n","      x = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', x) #remove various punctuations\n","      x = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', x) #remove url\n","      return x\n","\n","    preprocesser_a = lambda x: x.replace('\\n', ' ').strip().lower()\n","\n","    try:\n","        with open(path_to_file,\"r\") as dataset:\n","            reader = csv.DictReader((line.replace('\\0','') for line in dataset))\n","            for row in reader:\n","\n","                if num_examples and iterations == num_examples:\n","                  break\n","\n","                rdh = row[docstring_header]\n","                rah = row[ast_header]\n","                if rdh and rah:\n","                  d_words = preprocesser_d(rdh)\n","                  d_words_split = [word for word in d_words.split() if word]\n","                  d_words = ' '.join(d_words_split)\n","                  d_words_len = len(d_words_split)\n","\n","                  a_words = preprocesser_a(rah)\n","                  a_words_split = [a for a in a_words.split() if a and a not in ('(',')')]\n","                  a_words = ' '.join(a_words_split)\n","                  a_words_len = len(a_words_split)\n","\n","                  d_lens.append(d_words_len)\n","                  a_lens.append(a_words_len)\n","\n","                  # if 20 <= a_words_len <= 100 and d_words_len >= 2:\n","                  if 25 <= a_words_len and d_words_len >= 2:\n","                    # docstring_data.append(f\"{start_word} {d_words} {end_word}\\n\")\n","                    docstring_data.append(f\"{d_words}\\n\")\n","                    ast_data.append(f\"{a_words}\\n\")\n","                    d_lens_filtered.append(d_words_len)\n","                    a_lens_filtered.append(a_words_len)\n","                    iterations += 1\n","        \n","        indices = set()\n","        # if num_examples:\n","        #   indices = set(random.sample(range(iterations), num_examples))\n","        #   ast_data = [ast_data[i] for i in range(len(ast_data)) if i in indices]\n","        #   a_lens_filtered = [len(s) for s in ast_data]\n","        #   docstring_data = [docstring_data[i] for i in range(len(docstring_data)) if i in indices]\n","        #   d_lens_filtered = [len(s) for s in docstring_data]\n","\n","        print(\"Finished reading dataset\")\n","        print(\"d_lens max & avg\",max(d_lens),sum(d_lens)/len(d_lens))\n","        print(\"d_lens_f max & avg\",max(d_lens_filtered),sum(d_lens_filtered)/len(d_lens_filtered))\n","        print(\"a_lens max & avg\",max(a_lens),sum(a_lens)/len(a_lens))\n","        print(\"a_lens_f max & avg\",max(a_lens_filtered),sum(a_lens_filtered)/len(a_lens_filtered))\n","\n","        return ast_data, docstring_data, a_lens, d_lens, a_lens_filtered, d_lens_filtered, indices if len(indices) else set()\n","    except Exception as e:\n","        print('Error loading dataset', e)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NO_45J7Q9I-x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1597292766653,"user_tz":420,"elapsed":95750,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"9a0f9386-e2ca-4ce8-a923-f138e8fd03fd"},"source":["num_examples = 25000 #10000 #None #5000\n","x, y, x_lens, y_lens, x_lens_f, y_lens_f, indices = create_dataset(file_path, num_examples)\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1)\n","len(x_train),len(x_val),len(x_test),len(y_train),len(y_val),len(y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["alldata-allfields-withtypes-parens-uniques.csv 25000\n","Finished reading dataset\n","d_lens max & avg 56 8.670141673349372\n","d_lens_f max & avg 50 8.15028\n","a_lens max & avg 10313 131.96725474472066\n","a_lens_f max & avg 10313 153.45448\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(20250, 2250, 2500, 20250, 2250, 2500)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"zlEGNmYO06S9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1597292767445,"user_tz":420,"elapsed":96530,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"4858d5ff-b594-4f27-aebf-8453181acefe"},"source":["import numpy as np    \n","import matplotlib.pyplot as plt\n","plt.hist(x_lens, bins=np.arange(0,500,15),log=True,label=\"original\")\n","plt.hist(x_lens_f, bins=np.arange(0,500,15),log=True,label=\"filter\")\n","plt.legend();"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"UAUtsNmX1YDd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1597292768394,"user_tz":420,"elapsed":97470,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"769966f7-14ab-4b21-987f-bac8b50767b7"},"source":["import numpy as np    \n","import matplotlib.pyplot as plt\n","plt.hist(y_lens, bins=np.arange(0,250,5),log=True,label=\"original\")\n","plt.hist(y_lens_f, bins=np.arange(0,250,5),log=True,label=\"filter\")\n","plt.legend();"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Zqji6-0e196f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"status":"ok","timestamp":1597292860249,"user_tz":420,"elapsed":347,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"d137b12a-c7c8-4fd8-80fc-f3e3a34f6f5b"},"source":["x_train[0:25]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['functiondef args1 arguments arg constant str assign name store args0 attribute name load load assign name store args0 name load keyword str keyword str call args1 attribute attribute name load load load name load with withitem args1 attribute name load load name load call args0 attribute attribute name load load load createinstancecore(self: freezable) -> freezable\\n',\n"," 'functiondef args2 arguments arg arg constant str assign name store subscript args1 attribute attribute name load load load name load index unaryop usub int load if unaryop not name load return args0 name load assign name store args1 attribute attribute name load load load name load if unaryop not name load return args0 name load return args0 name load keyword args0 attribute name load load name load find rel=\"\"homepage\"\" and rel=\"\"download\"\" links in `page`\\n',\n"," 'functiondef args10 arguments arg arg arg arg arg arg arg arg arg arg nonetype nonetype str str nonetype int bool constant str assign name store args1 name load name load assign name store dict for name store name load assign name store args0 attribute name load load for name store name load assign name store args2 attribute name load load name load name load call args1 attribute subscript name load index name load load load subscript name load index str load assign subscript name load index name load store name load assign name store args2 attribute name load load args0 attribute name load load args0 attribute name load load assign name store list load if compare name load isnot nonetype assign name store args1 attribute name load load name load for tuple name store name store store args0 attribute name load load assign name store name load if compare args1 name load name load gt int assign name store list str load assign name store args0 name load keyword name load keyword name load keyword name load keyword dict str name load keyword name load keyword name load call args1 attribute name load load name load assign name store str assign tuple name store name store store args3 attribute name load load name load name load name load assign name store args5 attribute name load load list load name load name load name load name load keyword nonetype assign subscript name load index str store subscript name load index str load delete subscript name load index str del assign name store args2 attribute attribute name load load load name load name load keyword name load if compare name load is nonetype return dict for name store subscript name load index str load if boolop and compare subscript name load index str load eq str compare str notin subscript name load index str load call args1 attribute name load load subscript name load index str load assign name store dict for name store subscript name load index str load assign name store subscript name load index subscript name load index str load load assign name store subscript subscript name load index str load index str load if compare name load notin name load assign subscript name load index name load store args1 name load name load for tuple name store name store store args2 attribute name load load str list load if boolop and compare name load isnot nonetype compare name load noteq str call args1 attribute subscript subscript name load index name load load index name load load load args0 name load keyword name load keyword name load return name load finally will use `global_credentials` if both of previous ones are none.\\n',\n"," 'functiondef args1 arguments arg constant str functiondef args1 arguments arg return dict str str args0 attribute name load load keyword int keyword int args2 attribute attribute args0 name load load load int int args2 attribute name load load args1 attribute attribute name load load load str args2 attribute name load load args1 attribute name load load args1 name load str args1 attribute name load load args1 name load str assign tuple name store name store store args1 attribute name load load bytes call args2 attribute name load load bytes name load call args2 attribute name load load bytes name load call args2 attribute name load load bytes name load call args2 attribute name load load bytes name load l{transformjsonobject} transforms l{dict}s.\\n',\n"," 'functiondef args4 arguments arg arg arg arg str str bool constant str assign name store compare args0 attribute attribute name load load load eq args0 attribute args0 attribute attribute name load load load load if name load call args1 attribute name load load bool call args1 attribute name load load name load keyword bool call args1 attribute name load load name load keyword bool if name load call args0 attribute attribute name load load load call args3 attribute attribute name load load load name load name load name load resets the button to its original text and style. threadsafe.\\n',\n"," 'functiondef args4 arguments arg arg arg arg bool constant str assign name store nonetype assign name store list load for tuple name store name store store args1 name load name load assign name store binop str mod tuple name load subscript name load index int load subscript name load index int load load if name load if boolop or compare name load is nonetype compare name load noteq subscript name load index int load assign name store subscript name load index int load assign name store subscript name load index int load assign name store subscript name load index int load assign name store binop binop subscript name load index int load add str add name load assign name store binop binop subscript name load index int load add str add name load assign name store subscript name load index int load assign name store subscript name load index int load assign name store listcomp subscript name load index binop int add name load load comprehension name store attribute name load load call args1 attribute name load load args0 name load keyword name load keyword name load keyword name load keyword name load return name load truncates a sequence pair in place to the maximum length.\\n',\n"," 'functiondef args2 arguments arg arg name load constant str return subscript attribute name load load index name load load name load subscript name load index tuple name load subscript name load index name load load load load to be executed.\\n',\n"," 'functiondef args1 arguments arg constant str assign attribute name load store bool for tuple name store name store store args0 attribute attribute name load load load call args2 attribute name load load name load str call args0 attribute name load load assign name store int while compare name load lt binop int mult int assign name store bool for name store args0 attribute attribute name load load load if compare name load isnot nonetype assign name store boolop or name load args0 attribute name load load if unaryop not name load break call args1 attribute name load load int assign attribute name load store bool remove agent from the pool.\\n',\n"," 'functiondef args1 arguments arg constant str assign name store args1 name load args0 attribute name load load assign name store listcomp name load comprehension tuple name store name store store args1 name load name load compare subscript args0 attribute name load load index int load in name load assign name store add list nonetype load assign name store dict for name store subscript name load slice subscript name load index int load load for name store name load if args1 attribute name load load name load assign subscript name load index name load store subscript args1 attribute name load load name load index int load continue assign name store dictcomp subscript name load index name load load subscript name load slice binop name load add int subscript name load index binop name load add int load load comprehension tuple name store name store store args1 name load subscript name load slice unaryop usub int load return tuple name load name load load\\n',\n"," 'functiondef args1 arguments arg constant str assign name store dict str str list str str load list str str str str str str load for tuple name store name store store args1 name load name load assign name store args1 name load args2 name load attribute str load args1 name load args2 attribute name load load list str str str load binop name load add int assign name store binop args1 name load binop name load add int add args0 attribute name load load assign name store binop list binop name load add str load add listcomp binop binop name load add args1 name load name load add name load comprehension name store args2 name load int binop name load add int comprehension name store list str str load assign subscript name load index name load store binop name load add name load return name load the names are returned in a dictionary\\n',\n"," 'functiondef args1 arguments arg int constant str assign name store binop args1 name load args0 name load keyword str keyword str keyword str keyword name load add args0 name load for name store args2 name load int binop name load add int yield yield binop name load add args1 name load binop str mod tuple name load name load load generate filenames for the tests\\n',\n"," 'functiondef args3 arguments arg arg arg bool constant str for name store attribute name load load assign name store binop name load add str assign name store args2 name load name load name load if compare name load isnot nonetype assign name store args2 name load name load name load try call args1 attribute name load load name load excepthandler name load if name load continue raise attribute.\\n',\n"," 'functiondef args4 arguments arg arg arg arg bool constant str assign name store attribute name load load call args1 attribute name load load args0 name load call args1 attribute name load load args0 name load call args1 attribute name load load args0 name load assign name store args3 attribute attribute name load load load name load str joinedstr formattedvalue name load str if name load assign name store tuple args0 attribute name load load load assign name store tuple load call args1 attribute name load load name load keyword str keyword name load call args0 attribute name load load assign name store args1 name load generatorexp tuple name load name load load comprehension tuple name store name store name store store name load assign name store args1 name load generatorexp tuple name load name load load comprehension tuple name store name store name store name store store attribute name load load call args2 attribute name load load name load name load r matrix calculation test\\n',\n"," 'functiondef args1 arguments arg constant str return args3 name load attribute name load load str name load tested and finish. so this calls c{thunk} only once c{reactor} is running.\\n',\n"," 'functiondef args5 arguments arg arg arg arg arg constant str assign name store args1 attribute name load load args1 name load name load keyword name load assign name store args2 name load binop name load mult attribute name load load binop name load mult attribute name load load assign name store args2 name load binop name load mult attribute name load load binop name load mult attribute name load load assign name store binop args1 name load name load mult attribute name load load assign tuple name store name store name store name store store args2 attribute name load load name load name load if compare args1 name load name load eq int return name load assign name store args1 attribute name load load compare attribute name load load lt subscript name load index name load load assign subscript name load index subscript name load index name load load store bool return name load half-light radius of the ellipse (arcseconds)\\n',\n"," 'functiondef args2 arguments arg arg subscript name load index tuple name load str load load constant str if compare args1 name load name load eq name load assign name store args1 attribute name load load name load assign name store args2 name load name load attribute name load load assign name store args0 attribute name load load with withitem args0 attribute name load load name store assign name store args5 attribute attribute name load load load name load attribute name load load attribute name load load attribute attribute name load load load name load call args1 attribute name load load compare name load eq int return args2 name load name load attribute name load load str\\n',\n"," 'functiondef args2 arguments arg arg name load constant str assign name store args1 attribute name load load name load try assign name store args1 name load args2 attribute attribute name load load load attribute name load load name load excepthandler name load call args1 attribute name load load joinedstr formattedvalue name load str formattedvalue attribute name load load str formattedvalue name load str with withitem args1 attribute name load load name load keyword bool name store call args0 attribute name load load assign name store args0 name load for name store args0 attribute name load load keyword attribute name load load if compare binop args1 name load name load add args1 name load name load gt attribute name load load raise args2 name load name load attribute name load load call args1 attribute name load load name load call args3 attribute name load load name load name load name load return name load name load :param chunk_size: the amount of content retrieved from the url per request.\\n',\n"," 'functiondef args2 arguments arg name load arg name load bool constant str try return attribute args1 attribute name load load binop str mod name load keyword str load excepthandler name load if name load raise name load for tuple name store name store name store store args1 attribute name load load attribute name load load if boolop or args1 attribute name load load str compare args0 attribute name load load noteq args0 attribute name load load continue return attribute args1 attribute name load load binop str mod name load keyword str load raise name load subscript name load index name load load handles first initialization of the handler as a config profile switch.\\n',\n"," 'functiondef args3 arguments arg arg arg constant str try call args1 attribute name load load args3 attribute str load attribute name load load name load name load call args1 attribute attribute name load load load args1 attribute str load attribute name load load keyword name load keyword name load excepthandler name load call args1 attribute name load load args1 attribute str load name load raise args1 name load str name load name load make a post call to backbone recommender api.\\n',\n"," 'functiondef args12 arguments arg arg arg arg arg arg arg arg arg arg arg arg nonetype nonetype nonetype constant str assign attribute name load store name load assign attribute name load store args1 attribute name load load name load assign attribute name load store args1 attribute name load load name load assert compare attribute attribute name load load load eq attribute attribute name load load load assign attribute name load store nonetype if compare name load isnot nonetype assign attribute name load store args2 attribute name load load name load attribute attribute name load load load assign tuple attribute name load store attribute name load store attribute name load store store attribute attribute name load load load assign tuple attribute name load store attribute name load store store tuple name load name load load if compare name load isnot nonetype assign attribute name load store args1 attribute name load load name load assign attribute name load store args1 attribute name load load binop binop attribute name load load mult attribute name load load mult list attribute name load load load assign attribute attribute name load load store tuple attribute name load load attribute name load load load assign attribute name load store name load assert compare attribute name load load eq args1 name load attribute name load load assert args2 name load attribute name load load name load assign attribute name load store ifexp compare name load is nonetype dict name load assign attribute name load store args1 name load name load assign attribute name load store args1 name load name load reconstruct object from the dictionary in msonable format produced by as_dict.\\n',\n"," 'functiondef args5 arguments arg arg subscript name load index tuple list attribute name load load subscript name load index tuple name load name load load load load attribute name load load load load arg subscript name load index tuple name load name load load load arg name load arg name load nonetype nonetype nonetype constant str return args2 name load name load name load keyword name load keyword name load keyword name load str :return: the datasets for all levels.\\n',\n"," 'functiondef args1 arguments arg arg arg constant str if compare args1 name load attribute name load load eq int raise args1 name load str return args2 attribute name load load args1 name load args1 name load args0 attribute attribute name load load load starred name load load keyword name load dict: name/address pairs for opposite comms.\\n',\n"," 'functiondef args1 arguments arg constant str assign name store args0 attribute name load load call args2 attribute name load load str str assign tuple name store name store store args0 attribute name load load assign name store attribute name load load if name load if args1 attribute name load load str assign name store subscript name load slice unaryop usub int load call args1 name load str assign name store binop name load add str assign name store args1 attribute attribute name load load load dict str str str str str str str str str str str str str str str str str str assign name store args1 attribute name load load str assign name store args0 attribute args0 attribute attribute name load load load keyword name load keyword name load load test framehousestatusmonitordisableconfirmation.\\n',\n"," 'functiondef args3 arguments arg arg arg float constant str return args1 attribute name load load binop unaryop usub name load div binop binop int mult binop name load pow int add name load :param x: input with shape [n\\n',\n"," 'functiondef args2 arguments arg arg constant str assign name store args1 name load attribute name load load assign name store args1 attribute name load load args1 name load name load keyword attribute name load load assign name store subscript attribute name load load index int load assign attribute name load store args1 attribute name load load name load keyword int assign name store sub attribute name load load if compare attribute name load load is nonetype assign name store subscript attribute name load load index int load assign name store attribute name load load assign tuple name store name store name store store args2 name load name load name load keyword attribute name load load keyword name load assign attribute name load store name store binop binop name load pow int div binop name load sub int assign name store args0 attribute args1 attribute name load load name load keyword int keyword int load assign attribute name load store binop name load div name load assign attribute name load store name load if attribute name load load assign attribute name load store binop binop name load div subscript name load extslice slice index attribute name load load load mult args1 name load name load assign attribute name load store name load return name load n_samples : int\\n']"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"LccQyzR96rYY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"ok","timestamp":1597292936525,"user_tz":420,"elapsed":477,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"2a389514-93cf-4196-a72d-253ea60bee1e"},"source":["y_train[0:25]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['test sequencing center can be created with out name\\n',\n"," 'only ever yields unique items\\n',\n"," 'otherwise check if credentials is not none and uses them and\\n',\n"," 'l transformjsonobject transforms l list s\\n',\n"," 'displays specified message on button to let user know the action is in progress threadsafe\\n',\n"," 'creates examples for the training and dev sets\\n',\n"," 'it assumes data has the structure of a dictionary which maps orders executor instance to orders which need\\n',\n"," 'other metadata linked to agent removal\\n',\n"," 'split a data file into dict of header and sections\\n',\n"," 'generate all atomic orbital names that could be used by molpro\\n',\n"," 'return n distinct plot objects\\n',\n"," 'stores the index size tuple for the pack in the index sizes\\n',\n"," 'tests detectinvalid over the consensys benchmark suite\\n',\n"," 'interface address then the test won t be able to stop the reactor being\\n',\n"," 'r class float or numpy ndarray\\n',\n"," 'of the provided curve s order\\n',\n"," 'is greater than max size and the url is not cached\\n',\n"," 'returns a registered provider class with the specified modulename\\n',\n"," 'make a post call to backbone aggregator api\\n',\n"," 'initialize an instance of electronbands from the netcdf file filepath\\n',\n"," 'calling this method will trigger any lazy dataset instantiation\\n',\n"," 'defaults to none\\n',\n"," 'create home item\\n',\n"," 'implementation of a custom gather operation for faster backwards\\n',\n"," 'tested rank value\\n']"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"88Zyigc7SLTb","colab_type":"code","colab":{}},"source":["x_max_text_len = 300 #300 #140 #142 #142\n","y_max_text_len = 10 #50 #30\n","x_max_words = 200 #30000 #100 #15000 #31000 \n","y_max_words = 30000 #20000 #14500 #20000 #26000 #35000 #33000\n","y_min_occ = 0 #2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24kYeauSQlAN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1597292770458,"user_tz":420,"elapsed":99494,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"d8ec8f3b-2ff2-4f45-e616-8e3cefae316f"},"source":["import time\n","\n","open('x_train.txt', 'w').close()\n","with open(os.path.join(coding_dir, 'x_train.txt'), 'a+') as datafile:\n","  datafile.writelines(x_train)\n","  print(len(x_train))\n","\n","open('y_train.txt', 'w').close()\n","with open(os.path.join(coding_dir, 'y_train.txt'), 'a+') as datafile:\n","  datafile.writelines(y_train)\n","  print(len(y_train))\n","\n","open('x_val.txt', 'w').close()\n","with open(os.path.join(coding_dir, 'x_val.txt'), 'a+') as datafile:\n","  datafile.writelines(x_val)\n","  print(len(x_val))\n","\n","open('y_val.txt', 'w').close()\n","with open(os.path.join(coding_dir, 'y_val.txt'), 'a+') as datafile:\n","  datafile.writelines(y_val)\n","  print(len(y_val))\n","\n","open('x_test.txt', 'w').close()\n","with open(os.path.join(coding_dir, 'x_test.txt'), 'a+') as datafile:\n","  datafile.writelines(x_test)\n","  print(len(x_test))\n","\n","open('y_test.txt', 'w').close()\n","with open(os.path.join(coding_dir, 'y_test.txt'), 'a+') as datafile:\n","  datafile.writelines(y_test)\n","  print(len(y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20250\n","20250\n","2250\n","2250\n","2500\n","2500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d1A8D0qn9IeE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1597292770737,"user_tz":420,"elapsed":99765,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"7f9c7264-e3a9-4593-e7ff-3bd2d85b4170"},"source":["dataset.setOutput('y_train.txt',\n","             'train',\n","             type='text',\n","             id='target_text',\n","             tokenization=tokenize_y,\n","             build_vocabulary=True,\n","             pad_on_batch=True,\n","             sample_weights=True,\n","             max_text_len=y_max_text_len,\n","             max_words=y_max_words,\n","             min_occ=y_min_occ)\n","\n","dataset.setOutput('y_val.txt',\n","             'val',\n","             type='text',\n","             id='target_text',\n","             pad_on_batch=True,\n","             tokenization=tokenize_y,\n","             sample_weights=True,\n","             max_text_len=y_max_text_len,\n","             max_words=y_max_words)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:10] \tApplying tokenization function: \"tokenize_none\".\n","[13/08/2020 04:26:10] Creating vocabulary for data with data_id 'target_text'.\n","[13/08/2020 04:26:10] \t Total: 14289 unique words in 20250 sentences with a total of 165019 words.\n","[13/08/2020 04:26:10] Creating dictionary of 30000 most common words, covering 100.0% of the text.\n","[13/08/2020 04:26:10] Loaded \"train\" set outputs of data_type \"text\" with data_id \"target_text\" and length 20250.\n","[13/08/2020 04:26:10] \tApplying tokenization function: \"tokenize_none\".\n","[13/08/2020 04:26:10] Loaded \"val\" set outputs of data_type \"text\" with data_id \"target_text\" and length 2250.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"f72G9mHX9PPq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1597292772877,"user_tz":420,"elapsed":101897,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"4decea46-5708-4483-f04e-b83d159372ab"},"source":["dataset.setInput('x_train.txt',\n","            'train',\n","            type='text',\n","            id='source_text',\n","            pad_on_batch=True,\n","            tokenization=tokenize_x,\n","            build_vocabulary=True,\n","            fill='end',\n","            max_text_len=x_max_text_len,\n","            max_words=x_max_words,\n","            min_occ=0)\n","\n","dataset.setInput('x_val.txt',\n","            'val',\n","            type='text',\n","            id='source_text',\n","            pad_on_batch=True,\n","            tokenization=tokenize_x,\n","            fill='end',\n","            max_text_len=x_max_text_len,\n","            min_occ=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:10] \tApplying tokenization function: \"tokenize_none\".\n","[13/08/2020 04:26:11] Creating vocabulary for data with data_id 'source_text'.\n","[13/08/2020 04:26:12] \t Total: 19185 unique words in 20250 sentences with a total of 3100639 words.\n","[13/08/2020 04:26:12] Creating dictionary of 200 most common words, covering 98.0% of the text.\n","[13/08/2020 04:26:12] Loaded \"train\" set inputs of data_type \"text\" with data_id \"source_text\" and length 20250.\n","[13/08/2020 04:26:12] \tApplying tokenization function: \"tokenize_none\".\n","[13/08/2020 04:26:12] Loaded \"val\" set inputs of data_type \"text\" with data_id \"source_text\" and length 2250.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"jipVyl7f9NTz","colab_type":"text"},"source":["Similarly, we introduce the source text data, with the setInputs function. Again, when building the training split, we must construct the vocabulary."]},{"cell_type":"markdown","metadata":{"id":"AHvZimmm9U0p","colab_type":"text"},"source":["...and for the 'state_below' data. Note that: 1) The offset flat is set to 1, which means that the text will be shifted to the right 1 position. 2) During sampling time, we won't have this input. Hence, we 'hack' the dataset model by inserting an artificial input, of type 'ghost' for the validation split."]},{"cell_type":"code","metadata":{"id":"YiTM3y449ZFL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1597292773115,"user_tz":420,"elapsed":102127,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"429ad866-b89b-4e9c-ebae-9628874d88c7"},"source":["dataset.setInput('y_train.txt',\n","            'train',\n","            type='text',\n","            id='state_below',\n","            required=False,\n","            tokenization=tokenize_y,\n","            pad_on_batch=True,\n","            build_vocabulary='target_text',\n","            offset=1,\n","            fill='end',\n","            max_text_len=y_max_text_len,\n","            max_words=y_max_words)\n","dataset.setInput(None,\n","            'val',\n","            type='ghost',\n","            id='state_below',\n","            required=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:12] \tApplying tokenization function: \"tokenize_none\".\n","[13/08/2020 04:26:12] \tReusing vocabulary named \"target_text\" for data with data_id \"state_below\".\n","[13/08/2020 04:26:12] Loaded \"train\" set inputs of data_type \"text\" with data_id \"state_below\" and length 20250.\n","[13/08/2020 04:26:12] Loaded \"val\" set inputs of data_type \"ghost\" with data_id \"state_below\" and length 2250.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9H-1qb1ksD5Y","colab_type":"text"},"source":["We can also keep the literal source words (for replacing unknown words)."]},{"cell_type":"code","metadata":{"id":"akyexhdu8kry","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597292773323,"user_tz":420,"elapsed":102327,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"bd6f69d3-d709-4847-8752-035d56f819a3"},"source":["for split, input_text_filename in zip(['train', 'val'], ['x_train.txt','x_val.txt']):\n","  dataset.setRawInput(input_text_filename,\n","                split,\n","                type='file-name',\n","                id='raw_source_text',\n","                overwrite_split=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:13] Loaded \"train\" set inputs of type \"file-name\" with id \"raw_source_text\".\n","[13/08/2020 04:26:13] Loaded \"val\" set inputs of type \"file-name\" with id \"raw_source_text\".\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"lcYiuysd9cK4","colab_type":"text"},"source":["We also need to match the references with the inputs. Since we only have one reference per input sample, we set `repeat=1`."]},{"cell_type":"code","metadata":{"id":"1HQqnSwyi4Fs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597292773324,"user_tz":420,"elapsed":102319,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"ef05ecab-1e52-4eb5-d3e8-f7da1470af69"},"source":["keep_n_captions(dataset, repeat=1, n=1, set_names=['val'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:13] Keeping 1 captions per input on the val set.\n","[13/08/2020 04:26:13] Samples reduced to 2250 in val set.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"sDYhlBpR9vgi","colab_type":"text"},"source":["Finally, we can save our dataset instance for using in other experiments:"]},{"cell_type":"code","metadata":{"id":"YQ1VJhUg8fM6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597292774332,"user_tz":420,"elapsed":103319,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"5ca801cf-c006-42a6-cde7-a57682a8de35"},"source":["saveDataset(dataset, 'datasets')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:13] <<< Saving Dataset instance to datasets/Dataset_tutorial_dataset.pkl ... >>>\n","[13/08/2020 04:26:13] <<< Dataset instance saved >>>\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Yj8aYICU-eLH","colab_type":"text"},"source":["## 2. Creating and training a Neural Translation Model\n","Now, we'll create and train a Neural Machine Translation (NMT) model. Since there is a significant number of hyperparameters, we'll use the default ones, specified in the `config.py` file. Note that almost every hardcoded parameter is automatically set from config if we run  `main.py `.\n","\n","We'll create an `'AttentionRNNEncoderDecoder'` (a LSTM encoder-decoder with attention mechanism). Refer to the [`model_zoo.py`](https://github.com/lvapeab/nmt-keras/blob/master/nmt_keras/model_zoo.py) file for other models (e.g. Transformer). \n","\n","So first, let's import the model and the hyperparameters. We'll also load the dataset we stored in the previous section (not necessary as it is in memory, but as a demonstration):"]},{"cell_type":"code","metadata":{"id":"TszghyVO_M0B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597292776386,"user_tz":420,"elapsed":105364,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"48503534-1787-4536-816d-4fe9e9953d64"},"source":["os.chdir(coding_dir)\n","os.chdir('nmt-keras')\n","\n","from config import load_parameters\n","from nmt_keras.model_zoo import TranslationModel\n","from keras_wrapper.cnn_model import loadModel\n","from keras_wrapper.dataset import loadDataset\n","from keras_wrapper.extra.callbacks import PrintPerformanceMetricOnEpochEndOrEachNUpdates\n","params = load_parameters()\n","os.chdir(coding_dir)\n","dataset = loadDataset('datasets/Dataset_tutorial_dataset.pkl')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:16] <<< Loading Dataset instance from datasets/Dataset_tutorial_dataset.pkl ... >>>\n","[13/08/2020 04:26:16] <<< Dataset instance loaded >>>\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7MHVvMDYFmcQ","colab_type":"text"},"source":["Since the number of words in the dataset may be unknown beforehand, we must update the params information according to the dataset instance:\n"]},{"cell_type":"code","metadata":{"id":"BdnQBBs0kSJ2","colab_type":"code","colab":{}},"source":["params['num_examples'] = num_examples\n","params['y_max_text_len'] = y_max_text_len\n","params['x_max_text_len'] = x_max_text_len\n","params['tokenize_x'] = tokenize_x\n","params['tokenize_y'] = tokenize_y\n","params['x_max_words'] = x_max_words\n","params['y_max_words'] = y_max_words\n","params['y_min_occ'] = y_min_occ"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-P-awcq_5qt","colab_type":"code","colab":{}},"source":["import datetime\n","with open(f'indices-{datetime.datetime.now()}','a+') as indices_file:\n","  indices_file.write(\",\".join([str(i) for i in list(indices)]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3BeuRKiMV9D","colab_type":"code","colab":{}},"source":["#  Supported models: 'AttentionRNNEncoderDecoder' and 'Transformer'.\n","params['MODEL_TYPE'] = 'AttentionRNNEncoderDecoder'\n","# params['MODEL_TYPE'] = 'Transformer'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7FIJGybFm7C","colab_type":"code","colab":{}},"source":["params['INPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len['source_text']\n","params['OUTPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len['target_text']\n","is_transformer = params.get('ATTEND_ON_OUTPUT', 'transformer' in params['MODEL_TYPE'].lower())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"821qCbNTvH67","colab_type":"code","colab":{}},"source":["drop_p = 0.0 #0.2\n","# if not is_transformer:\n","#   params['RECURRENT_INPUT_DROPOUT_P'] = drop_p              \n","#   params['RECURRENT_DROPOUT_P'] = drop_p\n","# else:\n","#   params['DROPOUT_P'] = drop_p\n","\n","params['ATTENTION_DROPOUT_P'] = drop_p\n","params['DROPOUT_P'] = drop_p\n","params['USE_BATCH_NORMALIZATION'] = not drop_p      \n","\n","\n","params['USE_CUDNN'] = tf.test.is_gpu_available()\n","params['N_GPUS'] = 1 if tf.test.is_gpu_available() else 0\n","params['BEAM_SIZE'] = beam_size\n","params['TOKENIZATION_METHOD'] = tokenize_x\n","params['MAX_INPUT_TEXT_LEN'] = x_max_text_len\n","params['MAX_OUTPUT_TEXT_LEN'] = y_max_text_len\n","params['INPUT_VOCABULARY_SIZE'] = min(len(dataset.vocabulary['source_text']['idx2words']),x_max_words)\n","params['OUTPUT_VOCABULARY_SIZE'] = min(len(dataset.vocabulary['target_text']['idx2words']),y_max_words)\n","params['SRC_LAN'] = \"ast\"\n","params['TRG_LAN'] = \"en\"\n","params['MAXLEN_GIVEN_X'] = False\n","params['MINLEN_GIVEN_X'] = False\n","params['DATASET_NAME'] = 'ASTDocstring'\n","\n","params['TASK_NAME'] = params['DATASET_NAME']\n","params['DATA_ROOT_PATH'] = \"\"\n","params['PATIENCE'] = 3\n","params['PLOT_EVALUATION'] = True\n","params['LABEL_SMOOTHING'] = 0.1\n","\n","params['KERAS_METRICS'] = ['perplexity'] \n","params['EVAL_ON_SETS'] = ['train','val']\n","params['EPOCHS_FOR_SAVE'] = 5\n","\n","if not is_transformer:\n","  params['BATCH_SIZE'] = batch_size\n","  size_num = 512 \n","  params['SOURCE_TEXT_EMBEDDING_SIZE'] = size_num #64\n","  params['TARGET_TEXT_EMBEDDING_SIZE'] = size_num #//4 #64\n","  params['ENCODER_HIDDEN_SIZE'] = size_num #64\n","  params['DECODER_HIDDEN_SIZE'] = size_num #64\n","  params['ATTENTION_SIZE'] = params['DECODER_HIDDEN_SIZE']\n","  n_layers = 2\n","  params['N_LAYERS_ENCODER'] = n_layers\n","  params['N_LAYERS_DECODER'] = n_layers\n","  params['SKIP_VECTORS_HIDDEN_SIZE'] = params['TARGET_TEXT_EMBEDDING_SIZE']\n","  params['DEEP_OUTPUT_LAYERS'] = [('linear', size_num)] #64)]\n","  params['MODEL_SIZE'] = size_num #64\n","else:\n","  params['BATCH_SIZE'] = batch_size\n","  size_num = 512\n","  params['SOURCE_TEXT_EMBEDDING_SIZE'] = size_num #64\n","  params['TARGET_TEXT_EMBEDDING_SIZE'] = size_num\n","  params['ENCODER_HIDDEN_SIZE'] = size_num #64\n","  params['DECODER_HIDDEN_SIZE'] = size_num #64\n","  params['ATTENTION_SIZE'] = params['DECODER_HIDDEN_SIZE']\n","  params['N_HEADS'] = 4\n","  n_layers = 3\n","  params['N_LAYERS_ENCODER'] = n_layers\n","  params['N_LAYERS_DECODER'] = n_layers\n","  params['SKIP_VECTORS_HIDDEN_SIZE'] = params['TARGET_TEXT_EMBEDDING_SIZE']\n","  params['DEEP_OUTPUT_LAYERS'] = [('linear', size_num)] #64)]\n","  params['MODEL_SIZE'] = size_num #64\n","  # params['ATTENTION_MODE'] = 'dot'\n","\n","# params['NORMALIZE_SAMPLING'] = True\n","# params['SEARCH_PRUNING'] = True\n","params['LENGTH_PENALTY'] = True\n","params['COVERAGE_PENALTY'] = True\n","\n","params['OPTIMIZER'] = 'Adam'\n","if params['OPTIMIZER'] == 'SGD':\n","  params['LR'] = 0.01\n","  params['LR_REDUCE_EACH_EPOCHS'] = True\n","  params['LR_DECAY'] = 1\n","elif params['OPTIMIZER'] == 'Adam':\n","  params['LR'] = 0.0002 #0.001\n","#NOTE: model_size must == embed_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vrn6DXm60d7C","colab_type":"code","colab":{}},"source":["def set_model_name(params):\n","  if params['MODEL_TYPE'] == 'AttentionRNNEncoderDecoder':\n","    return params['TASK_NAME'] + '_' + params['SRC_LAN'] + params['TRG_LAN'] + '_' + params['MODEL_TYPE'] + \\\n","      '_src_emb_' + str(params['SOURCE_TEXT_EMBEDDING_SIZE']) + \\\n","      '_bidir_' + str(params['BIDIRECTIONAL_ENCODER']) + \\\n","      '_enc_' + params['ENCODER_RNN_TYPE'] + '_' + str(params['ENCODER_HIDDEN_SIZE']) + \\\n","      '_dec_' + params['DECODER_RNN_TYPE'] + '_' + str(params['DECODER_HIDDEN_SIZE']) + \\\n","      '_deepout_' + '_'.join([layer[0] for layer in params['DEEP_OUTPUT_LAYERS']]) + \\\n","      '_trg_emb_' + str(params['TARGET_TEXT_EMBEDDING_SIZE']) + \\\n","      '_' + params['OPTIMIZER'] + '_' + str(params['LR'])\n","  elif params['MODEL_NAME'] == 'Transformer':\n","    return params['TASK_NAME'] + '_' + params['SRC_LAN'] + params['TRG_LAN'] + '_' + params['MODEL_TYPE'] + \\\n","              '_model_size_' + str( params['MODEL_SIZE']) + \\\n","              '_ff_size_' + str( params['FF_SIZE']) + \\\n","              '_num_heads_' + str( params['N_HEADS']) + \\\n","              '_encoder_blocks_' + str( params['N_LAYERS_ENCODER']) + \\\n","              '_decoder_blocks_' + str( params['N_LAYERS_DECODER']) + \\\n","              '_deepout_' + '_'.join([layer[0] for layer in params['DEEP_OUTPUT_LAYERS']]) + \\\n","              '_' +  params['OPTIMIZER'] + '_' + str(params['LR'])\n","  else:\n","    return params['TASK_NAME'] + '_' + params['SRC_LAN'] + params['TRG_LAN'] + '_' +\\\n","                  params['MODEL_TYPE']  + '_' + params['OPTIMIZER'] + '_' + str(params['LR'])\n","\n","params['MODEL_NAME'] = set_model_name(params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c3a9XanxFpp7","colab_type":"text"},"source":["Now, we create a `TranslationModel` instance:\n"]},{"cell_type":"code","metadata":{"id":"2RYqrU6VFr8U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597292783766,"user_tz":420,"elapsed":112680,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"cc07eab6-d138-4eda-d83d-29c30633abba"},"source":["nmt_model = TranslationModel(params,\n","                             model_type=params['MODEL_TYPE'], \n","                             model_name='tutorial_model',\n","                             vocabularies=dataset.vocabulary,\n","                             store_path='trained_models/tutorial_model/',\n","                             verbose=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:17] <<< Building AttentionRNNEncoderDecoder Translation_Model >>>\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:650: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:17] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:650: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4786: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:17] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4786: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:157: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:17] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:157: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3561: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:21] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3561: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["-----------------------------------------------------------------------------------\n","\t\tTranslationModel instance\n","-----------------------------------------------------------------------------------\n","_model_type: AttentionRNNEncoderDecoder\n","name: tutorial_model\n","model_path: trained_models/tutorial_model/\n","verbose: True\n","\n","Params:\n","\tACCUMULATE_GRADIENTS: 1\n","\tADDITIONAL_OUTPUT_MERGE_MODE: Add\n","\tALIGN_FROM_RAW: True\n","\tALPHA_FACTOR: 0.6\n","\tAMSGRAD: False\n","\tAPPLY_DETOKENIZATION: False\n","\tATTENTION_DROPOUT_P: 0.0\n","\tATTENTION_MODE: add\n","\tATTENTION_SIZE: 512\n","\tBATCH_NORMALIZATION_MODE: 1\n","\tBATCH_SIZE: 200\n","\tBEAM_SEARCH: True\n","\tBEAM_SIZE: 6\n","\tBETA_1: 0.9\n","\tBETA_2: 0.999\n","\tBIDIRECTIONAL_DEEP_ENCODER: True\n","\tBIDIRECTIONAL_ENCODER: True\n","\tBIDIRECTIONAL_MERGE_MODE: concat\n","\tBPE_CODES_PATH: examples/EuTrans//training_codes.joint\n","\tCLASSIFIER_ACTIVATION: softmax\n","\tCLIP_C: 5.0\n","\tCLIP_V: 0.0\n","\tCOVERAGE_NORM_FACTOR: 0.2\n","\tCOVERAGE_PENALTY: True\n","\tDATASET_NAME: ASTDocstring\n","\tDATASET_STORE_PATH: datasets/\n","\tDATA_AUGMENTATION: False\n","\tDATA_ROOT_PATH: \n","\tDECODER_HIDDEN_SIZE: 512\n","\tDECODER_RNN_TYPE: ConditionalLSTM\n","\tDEEP_OUTPUT_LAYERS: [('linear', 512)]\n","\tDETOKENIZATION_METHOD: detokenize_none\n","\tDOUBLE_STOCHASTIC_ATTENTION_REG: 0.0\n","\tDROPOUT_P: 0.0\n","\tEARLY_STOP: True\n","\tEMBEDDINGS_FREQ: 1\n","\tENCODER_HIDDEN_SIZE: 512\n","\tENCODER_RNN_TYPE: LSTM\n","\tEPOCHS_FOR_SAVE: 5\n","\tEPSILON: 1e-08\n","\tEVAL_EACH: 1\n","\tEVAL_EACH_EPOCHS: True\n","\tEVAL_ON_SETS: ['train', 'val']\n","\tEXTRA_NAME: \n","\tFF_SIZE: 128\n","\tFILL: end\n","\tFORCE_RELOAD_VOCABULARY: False\n","\tGLOSSARY: None\n","\tGRU_RESET_AFTER: True\n","\tHEURISTIC: 0\n","\tHOMOGENEOUS_BATCHES: False\n","\tINIT_ATT: glorot_uniform\n","\tINIT_FUNCTION: glorot_uniform\n","\tINIT_LAYERS: ['tanh']\n","\tINNER_INIT: orthogonal\n","\tINPUTS_IDS_DATASET: ['source_text', 'state_below']\n","\tINPUTS_IDS_MODEL: ['source_text', 'state_below']\n","\tINPUTS_TYPES_DATASET: ['text-features', 'text-features']\n","\tINPUT_VOCABULARY_SIZE: 200\n","\tJOINT_BATCHES: 4\n","\tKERAS_METRICS: ['perplexity']\n","\tLABEL_SMOOTHING: 0.1\n","\tLENGTH_NORM_FACTOR: 0.2\n","\tLENGTH_PENALTY: True\n","\tLOG_DIR: tensorboard_logs\n","\tLOSS: categorical_crossentropy\n","\tLR: 0.0002\n","\tLR_DECAY: None\n","\tLR_GAMMA: 0.8\n","\tLR_HALF_LIFE: 100\n","\tLR_REDUCER_EXP_BASE: -0.5\n","\tLR_REDUCER_TYPE: exponential\n","\tLR_REDUCE_EACH_EPOCHS: False\n","\tLR_START_REDUCTION_ON_EPOCH: 0\n","\tMAPPING: examples/EuTrans//mapping.es_en.pkl\n","\tMAXLEN_GIVEN_X: False\n","\tMAXLEN_GIVEN_X_FACTOR: 2\n","\tMAX_EPOCH: 500\n","\tMAX_INPUT_TEXT_LEN: 300\n","\tMAX_OUTPUT_TEXT_LEN: 10\n","\tMAX_OUTPUT_TEXT_LEN_TEST: 150\n","\tMAX_PLOT_Y: 100.0\n","\tMETRICS: ['sacrebleu', 'perplexity']\n","\tMINLEN_GIVEN_X: False\n","\tMINLEN_GIVEN_X_FACTOR: 3\n","\tMIN_DELTA: 0.0\n","\tMIN_LR: 1e-09\n","\tMIN_OCCURRENCES_INPUT_VOCAB: 0\n","\tMIN_OCCURRENCES_OUTPUT_VOCAB: 0\n","\tMODE: training\n","\tMODEL_NAME: ASTDocstring_asten_AttentionRNNEncoderDecoder_src_emb_512_bidir_True_enc_LSTM_512_dec_ConditionalLSTM_512_deepout_linear_trg_emb_512_Adam_0.0002\n","\tMODEL_SIZE: 512\n","\tMODEL_TYPE: AttentionRNNEncoderDecoder\n","\tMOMENTUM: 0.0\n","\tMULTIHEAD_ATTENTION_ACTIVATION: linear\n","\tNESTEROV_MOMENTUM: False\n","\tNOISE_AMOUNT: 0.01\n","\tNORMALIZE_SAMPLING: False\n","\tN_GPUS: 1\n","\tN_HEADS: 8\n","\tN_LAYERS_DECODER: 2\n","\tN_LAYERS_ENCODER: 2\n","\tN_SAMPLES: 5\n","\tOPTIMIZED_SEARCH: True\n","\tOPTIMIZER: Adam\n","\tOUTPUTS_IDS_DATASET: ['target_text']\n","\tOUTPUTS_IDS_MODEL: ['target_text']\n","\tOUTPUTS_TYPES_DATASET: ['text-features']\n","\tOUTPUT_VOCABULARY_SIZE: 14292\n","\tPAD_ON_BATCH: True\n","\tPARALLEL_LOADERS: 1\n","\tPATIENCE: 3\n","\tPLOT_EVALUATION: True\n","\tPOS_UNK: True\n","\tREBUILD_DATASET: True\n","\tRECURRENT_DROPOUT_P: 0.0\n","\tRECURRENT_INPUT_DROPOUT_P: 0.0\n","\tRECURRENT_WEIGHT_DECAY: 0.0\n","\tREGULARIZATION_FN: L2\n","\tRELOAD: 0\n","\tRELOAD_EPOCH: True\n","\tRHO: 0.9\n","\tSAMPLE_EACH_UPDATES: 300\n","\tSAMPLE_ON_SETS: ['train', 'val']\n","\tSAMPLE_WEIGHTS: True\n","\tSAMPLING: max_likelihood\n","\tSAMPLING_SAVE_MODE: list\n","\tSAVE_EACH_EVALUATION: True\n","\tSCALE_SOURCE_WORD_EMBEDDINGS: False\n","\tSCALE_TARGET_WORD_EMBEDDINGS: False\n","\tSEARCH_PRUNING: False\n","\tSKIP_VECTORS_HIDDEN_SIZE: 512\n","\tSKIP_VECTORS_SHARED_ACTIVATION: tanh\n","\tSOURCE_TEXT_EMBEDDING_SIZE: 512\n","\tSRC_LAN: ast\n","\tSRC_PRETRAINED_VECTORS: None\n","\tSRC_PRETRAINED_VECTORS_TRAINABLE: True\n","\tSTART_EVAL_ON_EPOCH: 1\n","\tSTART_SAMPLING_ON_EPOCH: 1\n","\tSTOP_METRIC: Bleu_4\n","\tSTORE_PATH: trained_models/EuTrans_esen_AttentionRNNEncoderDecoder_src_emb_32_bidir_True_enc_LSTM_32_dec_ConditionalLSTM_32_deepout_linear_trg_emb_32_Adam_0.001/\n","\tTARGET_TEXT_EMBEDDING_SIZE: 512\n","\tTASK_NAME: ASTDocstring\n","\tTEMPERATURE: 1\n","\tTENSORBOARD: True\n","\tTEXT_FILES: {'train': 'training.', 'val': 'dev.', 'test': 'test.'}\n","\tTIE_EMBEDDINGS: False\n","\tTOKENIZATION_METHOD: tokenize_none\n","\tTOKENIZE_HYPOTHESES: True\n","\tTOKENIZE_REFERENCES: True\n","\tTRAINABLE_DECODER: True\n","\tTRAINABLE_ENCODER: True\n","\tTRAIN_ON_TRAINVAL: False\n","\tTRG_LAN: en\n","\tTRG_PRETRAINED_VECTORS: None\n","\tTRG_PRETRAINED_VECTORS_TRAINABLE: True\n","\tUSE_BATCH_NORMALIZATION: True\n","\tUSE_CUDNN: True\n","\tUSE_L1: False\n","\tUSE_L2: False\n","\tUSE_NOISE: False\n","\tUSE_PRELU: False\n","\tUSE_TF_OPTIMIZER: True\n","\tVERBOSE: 1\n","\tWARMUP_EXP: -1.5\n","\tWEIGHT_DECAY: 0.0001\n","\tWRITE_VALID_SAMPLES: True\n","\tnum_examples: 25000\n","\ttokenize_x: tokenize_none\n","\ttokenize_y: tokenize_none\n","\tx_max_text_len: 300\n","\tx_max_words: 200\n","\ty_max_text_len: 10\n","\ty_max_words: 30000\n","\ty_min_occ: 0\n","-----------------------------------------------------------------------------------\n","Model: \"tutorial_model_training\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","source_text (InputLayer)        (None, None)         0                                            \n","__________________________________________________________________________________________________\n","source_word_embedding (Embeddin (None, None, 512)    102400      source_text[0][0]                \n","__________________________________________________________________________________________________\n","src_embedding_batch_normalizati (None, None, 512)    2048        source_word_embedding[0][0]      \n","__________________________________________________________________________________________________\n","remove_mask_1 (RemoveMask)      (None, None, 512)    0           src_embedding_batch_normalization\n","__________________________________________________________________________________________________\n","bidirectional_encoder_LSTM (Bid (None, None, 1024)   4202496     remove_mask_1[0][0]              \n","__________________________________________________________________________________________________\n","annotations_batch_normalization (None, None, 1024)   4096        bidirectional_encoder_LSTM[0][0] \n","__________________________________________________________________________________________________\n","bidirectional_encoder_1 (Bidire (None, None, 1024)   6299648     annotations_batch_normalization[0\n","__________________________________________________________________________________________________\n","annotations_1_batch_normalizati (None, None, 1024)   4096        bidirectional_encoder_1[0][0]    \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, None, 1024)   0           annotations_batch_normalization[0\n","                                                                 annotations_1_batch_normalization\n","__________________________________________________________________________________________________\n","source_text_mask (GetMask)      (None, None, 512)    0           src_embedding_batch_normalization\n","__________________________________________________________________________________________________\n","annotations (ApplyMask)         (None, None, 1024)   0           add_1[0][0]                      \n","                                                                 source_text_mask[0][0]           \n","__________________________________________________________________________________________________\n","state_below (InputLayer)        (None, None)         0                                            \n","__________________________________________________________________________________________________\n","ctx_mean (MaskedMean)           (None, 1024)         0           annotations[0][0]                \n","__________________________________________________________________________________________________\n","target_word_embedding (Embeddin (None, None, 512)    7317504     state_below[0][0]                \n","__________________________________________________________________________________________________\n","initial_state (Dense)           (None, 512)          524800      ctx_mean[0][0]                   \n","__________________________________________________________________________________________________\n","initial_memory (Dense)          (None, 512)          524800      ctx_mean[0][0]                   \n","__________________________________________________________________________________________________\n","state_below_batch_normalization (None, None, 512)    2048        target_word_embedding[0][0]      \n","__________________________________________________________________________________________________\n","initial_state_batch_normalizati (None, 512)          2048        initial_state[0][0]              \n","__________________________________________________________________________________________________\n","initial_memory_batch_normalizat (None, 512)          2048        initial_memory[0][0]             \n","__________________________________________________________________________________________________\n","decoder_AttConditionalLSTMCond  [(None, None, 512),  6034433     state_below_batch_normalization[0\n","                                                                 annotations[0][0]                \n","                                                                 initial_state_batch_normalization\n","                                                                 initial_memory_batch_normalizatio\n","__________________________________________________________________________________________________\n","proj_h0_batch_normalization (Ba (None, None, 512)    2048        decoder_AttConditionalLSTMCond[0]\n","__________________________________________________________________________________________________\n","permute_general_1 (PermuteGener multiple             0           decoder_AttConditionalLSTMCond[0]\n","                                                                 logit_ctx[0][0]                  \n","__________________________________________________________________________________________________\n","decoder_LSTMCond1 (LSTMCond)    [(None, None, 512),  4196352     proj_h0_batch_normalization[0][0]\n","                                                                 permute_general_1[0][0]          \n","                                                                 initial_state_batch_normalization\n","                                                                 initial_memory_batch_normalizatio\n","__________________________________________________________________________________________________\n","proj_h1_batch_normalization (Ba (None, None, 512)    2048        decoder_LSTMCond1[0][0]          \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, None, 512)    0           proj_h0_batch_normalization[0][0]\n","                                                                 proj_h1_batch_normalization[0][0]\n","__________________________________________________________________________________________________\n","logit_ctx (TimeDistributed)     (None, None, 512)    524800      decoder_AttConditionalLSTMCond[0]\n","__________________________________________________________________________________________________\n","logit_lstm (TimeDistributed)    (None, None, 512)    262656      add_2[0][0]                      \n","__________________________________________________________________________________________________\n","logit_emb (TimeDistributed)     (None, None, 512)    262656      state_below_batch_normalization[0\n","__________________________________________________________________________________________________\n","out_layer_mlp_batch_normalizati (None, None, 512)    2048        logit_lstm[0][0]                 \n","__________________________________________________________________________________________________\n","out_layer_ctx_batch_normalizati (None, None, 512)    2048        permute_general_1[1][0]          \n","__________________________________________________________________________________________________\n","out_layer_emb_batch_normalizati (None, None, 512)    2048        logit_emb[0][0]                  \n","__________________________________________________________________________________________________\n","additional_input (Add)          (None, None, 512)    0           out_layer_mlp_batch_normalization\n","                                                                 out_layer_ctx_batch_normalization\n","                                                                 out_layer_emb_batch_normalization\n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, None, 512)    0           additional_input[0][0]           \n","__________________________________________________________________________________________________\n","linear_0 (TimeDistributed)      (None, None, 512)    262656      activation_1[0][0]               \n","__________________________________________________________________________________________________\n","out_layer_linear_0_batch_normal (None, None, 512)    2048        linear_0[0][0]                   \n","__________________________________________________________________________________________________\n","target_text (TimeDistributed)   (None, None, 14292)  7331796     out_layer_linear_0_batch_normaliz\n","==================================================================================================\n","Total params: 37,875,669\n","Trainable params: 37,861,333\n","Non-trainable params: 14,336\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /content/drive/My Drive/Coding stuff/nmt-keras/nmt_keras/model_zoo.py:213: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:23] From /content/drive/My Drive/Coding stuff/nmt-keras/nmt_keras/model_zoo.py:213: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","[13/08/2020 04:26:23] Preparing optimizer and compiling. Optimizer configuration: \n","\t LR: 0.0002\n","\t LOSS: categorical_crossentropy\n","\t BETA_1: 0.9\n","\t BETA_2: 0.999\n","\t EPSILON: 1e-08\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1192: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:23] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1192: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"G8Wi-z_Pzatf","colab_type":"code","colab":{}},"source":["wandb.log({'params': params})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pKQqWOneGD_3","colab_type":"text"},"source":["Next, we must define the inputs and outputs mapping from our Dataset instance to our model:\n"]},{"cell_type":"code","metadata":{"id":"VqEqWxYHGIM5","colab_type":"code","colab":{}},"source":["inputMapping = dict()\n","for i, id_in in enumerate(params['INPUTS_IDS_DATASET']):\n","    pos_source = dataset.ids_inputs.index(id_in)\n","    id_dest = nmt_model.ids_inputs[i]\n","    inputMapping[id_dest] = pos_source\n","nmt_model.setInputsMapping(inputMapping)\n","\n","outputMapping = dict()\n","for i, id_out in enumerate(params['OUTPUTS_IDS_DATASET']):\n","    pos_target = dataset.ids_outputs.index(id_out)\n","    id_dest = nmt_model.ids_outputs[i]\n","    outputMapping[id_dest] = pos_target\n","nmt_model.setOutputsMapping(outputMapping)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NKPW2hv8GKMj","colab_type":"text"},"source":["We can add some callbacks for controlling the training (e.g. Sampling each N updates, early stop, learning rate annealing...). For instance, let's build a sampling callback. After each epoch, it will compute the BLEU scores on the development set using the sacreBLEU package. We need to pass some configuration variables to the callback (in the extra_vars dictionary):\n"]},{"cell_type":"code","metadata":{"id":"7MtMvSoAGNHb","colab_type":"code","colab":{}},"source":["search_params = {\n","    'language': 'en',\n","    'tokenize_f': eval('dataset.' + tokenize_x),\n","    'beam_size': beam_size,\n","    'optimized_search': True,\n","    'model_inputs': params['INPUTS_IDS_MODEL'],\n","    'model_outputs': params['OUTPUTS_IDS_MODEL'],\n","    'dataset_inputs':  params['INPUTS_IDS_DATASET'],\n","    'dataset_outputs':  params['OUTPUTS_IDS_DATASET'],\n","    'n_parallel_loaders': n_parallel_loaders,\n","    'maxlen': y_max_text_len,\n","    'normalize_probs': True,\n","    'pos_unk': True and not is_transformer,  # Pos_unk is unimplemented for transformer models\n","    'heuristic': 0,\n","    'state_below_maxlen': -1,\n","    'attend_on_output': is_transformer,\n","    'val': {'references': dataset.extra_variables['val']['target_text']}\n","  }\n","\n","vocab = dataset.vocabulary['target_text']['idx2words']\n","callbacks = []\n","input_text_id = params['INPUTS_IDS_DATASET'][0]\n","\n","callbacks.append(PrintPerformanceMetricOnEpochEndOrEachNUpdates(nmt_model,\n","                                                                dataset,\n","                                                                gt_id='target_text',\n","                                                                metric_name=['sacrebleu'],\n","                                                                set_name=['val'],\n","                                                                batch_size=batch_size,\n","                                                                each_n_epochs=1,\n","                                                                extra_vars=search_params,\n","                                                                reload_epoch=0,\n","                                                                is_text=True,\n","                                                                input_text_id=input_text_id,\n","                                                                index2word_y=vocab,\n","                                                                sampling_type='max_likelihood',\n","                                                                beam_search=True,\n","                                                                save_path=nmt_model.model_path,\n","                                                                start_eval_on_epoch=0,\n","                                                                write_samples=True,\n","                                                                write_type='list',\n","                                                                verbose=True))\n","callbacks.append(WandbCallback(monitor='Bleu_4',save_model=True))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vo-kOSLlGQux","colab_type":"text"},"source":["Now we are ready to train. Let's set up some training parameters...\n"]},{"cell_type":"code","metadata":{"id":"_-oborMLGUMP","colab_type":"code","colab":{}},"source":["n_epochs = 35\n","training_params = {'n_epochs': n_epochs,\n","                   'batch_size': batch_size,\n","                   'maxlen': y_max_text_len,\n","                   'epochs_for_save': 1,\n","                   'verbose': 1,\n","                   'eval_on_sets': [], \n","                   'n_parallel_loaders': n_parallel_loaders,\n","                   'extra_callbacks': callbacks,\n","                   'reload_epoch': 0,\n","                   'epoch_offset': 0}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z7m3oR5RGVDp","colab_type":"text"},"source":["And train!\n"]},{"cell_type":"code","metadata":{"id":"PcyAKL4cGai4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1597292833521,"user_tz":420,"elapsed":162390,"user":{"displayName":"Dhanush Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAzOHIPcMJjso9YEiyG7rBGdSGeY_AlSMnoxQgm0U=s64","userId":"02219766938693729498"}},"outputId":"b2d416ff-2770-4a65-97d9-5e470e51993d"},"source":["nmt_model.trainNet(dataset, training_params)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13/08/2020 04:26:29] <<< Training model >>>\n","[13/08/2020 04:26:29] Training parameters: { \n","\tbatch_size: 200\n","\tclass_weights: None\n","\tda_enhance_list: []\n","\tda_patch_type: resize_and_rndcrop\n","\tdata_augmentation: False\n","\teach_n_epochs: 1\n","\tepoch_offset: 0\n","\tepochs_for_save: 1\n","\teval_on_epochs: True\n","\teval_on_sets: []\n","\textra_callbacks: [<keras_wrapper.extra.callbacks.EvalPerformance object at 0x7fdae2760828>, <wandb.keras.WandbCallback object at 0x7fdae27607f0>]\n","\thomogeneous_batches: False\n","\tinitial_lr: 1.0\n","\tjoint_batches: 4\n","\tlr_decay: None\n","\tlr_gamma: 0.1\n","\tlr_half_life: 50000\n","\tlr_reducer_exp_base: 0.5\n","\tlr_reducer_type: linear\n","\tlr_warmup_exp: -1.5\n","\tmaxlen: 10\n","\tmean_substraction: False\n","\tmetric_check: None\n","\tmin_delta: 0.0\n","\tmin_lr: 1e-09\n","\tn_epochs: 35\n","\tn_gpus: 1\n","\tn_parallel_loaders: 3\n","\tnormalization_type: None\n","\tnormalize: False\n","\tnum_iterations_val: None\n","\tpatience: 0\n","\tpatience_check_split: val\n","\treduce_each_epochs: True\n","\treload_epoch: 0\n","\tshuffle: True\n","\tstart_eval_on_epoch: 0\n","\tstart_reduction_on_epoch: 0\n","\ttensorboard: False\n","\ttensorboard_params: {'log_dir': 'tensorboard_logs', 'histogram_freq': 0, 'batch_size': 50, 'write_graph': True, 'write_grads': False, 'write_images': False, 'embeddings_freq': 0, 'embeddings_layer_names': None, 'embeddings_metadata': None, 'update_freq': 'epoch'}\n","\tverbose: 1\n","\two_da_patch_type: whole\n","}\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3315: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:34] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3315: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:292: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:34] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:292: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:299: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:34] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:299: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:312: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:34] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:312: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:34] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","[13/08/2020 04:26:34] Starting dataLoad_process_0...\n","[13/08/2020 04:26:34] Starting dataLoad_process_1...\n","[13/08/2020 04:26:34] Starting dataLoad_process_2...\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:328: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[13/08/2020 04:26:38] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:328: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/35\n"],"name":"stdout"},{"output_type":"stream","text":["Process Process-3:\n","Traceback (most recent call last):\n","Process Process-4:\n","Process Process-2:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_wrapper/dataset.py\", line 51, in dataLoad\n","    while out_queue.qsize() > max_queue_len:\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_wrapper/dataset.py\", line 51, in dataLoad\n","    while out_queue.qsize() > max_queue_len:\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_wrapper/utils.py\", line 81, in qsize\n","    return self.queue.qsize()\n","  File \"<string>\", line 2, in qsize\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_wrapper/utils.py\", line 81, in qsize\n","    return self.queue.qsize()\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_wrapper/dataset.py\", line 51, in dataLoad\n","    while out_queue.qsize() > max_queue_len:\n","  File \"<string>\", line 2, in qsize\n","  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n","    kind, result = conn.recv()\n","  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 756, in _callmethod\n","    conn.send((self._id, methodname, args, kwds))\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n","    self._send_bytes(_ForkingPickler.dumps(obj))\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_wrapper/utils.py\", line 81, in qsize\n","    return self.queue.qsize()\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n","    buf = self._recv_bytes()\n","  File \"<string>\", line 2, in qsize\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n","    self._send(header + buf)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n","    n = write(self._handle, buf)\n","  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n","    kind, result = conn.recv()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n","    buf = self._recv_bytes()\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","KeyboardInterrupt\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-eb54cafee91f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnmt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_wrapper/cnn_model.py\u001b[0m in \u001b[0;36mtrainNet\u001b[0;34m(self, ds, parameters, out_name)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         self.__train(ds,\n\u001b[0;32m--> 667\u001b[0;31m                      params)\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<<< Finished training model >>>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_wrapper/cnn_model.py\u001b[0m in \u001b[0;36m__train\u001b[0;34m(self, ds, params, state)\u001b[0m\n\u001b[1;32m    887\u001b[0m                                          \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_parallel_loaders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                                          \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                                          initial_epoch=params['epoch_offset'])\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m     def __train_from_samples(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1769\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1771\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 3264\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   3265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"knMMNtC_NiGZ","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hq3_MyX3A4XV","colab_type":"text"},"source":["## 3. Decoding with a trained Neural Machine Translation Model\n","\n","Now, we'll load from disk the model we just trained and we'll apply it for translating new text. In this case, we want to translate the 'test' split from our dataset.\n","\n","Since we want to translate a new data split ('test') we must add it to the dataset instance, just as we did before (at the first tutorial). In case we also had the refences of the test split and we wanted to evaluate it, we can add it to the dataset. Note that this is not mandatory and we could just predict without evaluating."]},{"cell_type":"markdown","metadata":{"id":"SFmG3Y5_d-1c","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"2H-jXRq4BGm_","colab_type":"code","colab":{}},"source":["dataset.setInput('x_test.txt',\n","            'test',\n","            type='text',\n","            id='source_text',\n","            pad_on_batch=True,\n","            tokenization=tokenize_x,\n","            fill='end',\n","            max_text_len=x_max_text_len,\n","            min_occ=0)\n","\n","dataset.setInput(None,\n","            'test',\n","            type='ghost',\n","            id='state_below',\n","            required=False)\n","\n","dataset.setRawInput('x_test.txt',\n","              'test',\n","              type='file-name',\n","              id='raw_source_text',\n","              overwrite_split=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wUZveIgLCzlq","colab_type":"text"},"source":["Now, let's load the translation model. Suppose we want to load the model saved at the end of the epoch 4:\n"]},{"cell_type":"code","metadata":{"id":"8hgOSknZC2lh","colab_type":"code","colab":{}},"source":["params['INPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len[params['INPUTS_IDS_DATASET'][0]]\n","params['OUTPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len[params['OUTPUTS_IDS_DATASET'][0]]\n","\n","# Load model\n","#n_epochs\n","epoch_load = -1\n","try:\n","  nmt_model = loadModel(os.path.join(coding_dir,'trained_models/tutorial_model'),n_epochs)\n","  epoch_load = n_epochs\n","except:\n","  epoch_load = 10\n","  nmt_model = loadModel(os.path.join(coding_dir,'trained_models/tutorial_model'),epoch_load)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"piDc_y0pC5la","colab_type":"text"},"source":["Once we loaded the model, we just have to invoke the sampling method (in this case, the Beam Search algorithm) for the 'test' split:\n"]},{"cell_type":"code","metadata":{"id":"2FBT1HWYC9ip","colab_type":"code","colab":{}},"source":["is_transformer = params.get('ATTEND_ON_OUTPUT', 'transformer' in params['MODEL_TYPE'].lower())\n","\n","params_prediction = {\n","    'language': 'en',\n","    'tokenize_f': eval('dataset.' + tokenize_x),\n","    'beam_size': beam_size,\n","    'optimized_search': True,\n","    'model_inputs': params['INPUTS_IDS_MODEL'],\n","    'model_outputs': params['OUTPUTS_IDS_MODEL'],\n","    'dataset_inputs':  params['INPUTS_IDS_DATASET'],\n","    'dataset_outputs':  params['OUTPUTS_IDS_DATASET'],\n","    'n_parallel_loaders': n_parallel_loaders,\n","    'maxlen': y_max_text_len,\n","    'normalize_probs': True,\n","    'pos_unk': True and not is_transformer,\n","    'heuristic': 0,\n","    'state_below_maxlen': -1,\n","    'predict_on_sets': ['test'],\n","    'verbose': 0,\n","    'attend_on_output': is_transformer\n","  }\n","predictions = nmt_model.predictBeamSearchNet(dataset, params_prediction)['test']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S2JcEpFJDTDs","colab_type":"text"},"source":["Up to now, in the variable 'predictions', we have the indices of the words of the hypotheses. We must decode them into words. For doing this, we'll use the dictionary stored in the dataset object:\n"]},{"cell_type":"code","metadata":{"id":"4EGTAOFXDYLX","colab_type":"code","colab":{}},"source":["from keras_wrapper.utils import decode_predictions_beam_search\n","vocab = dataset.vocabulary['target_text']['idx2words']\n","samples = predictions['samples'] # Get word indices from the samples.\n","\n","predictions = decode_predictions_beam_search(samples,  \n","                                             vocab,\n","                                             verbose=params['VERBOSE'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7MZVhj0IDd93","colab_type":"text"},"source":["Finally, we store the hypotheses:\n","\n"]},{"cell_type":"code","metadata":{"id":"kznqPYZMDg8o","colab_type":"code","colab":{}},"source":["filepath = 'test.pred'\n","from keras_wrapper.extra.read_write import list2file\n","list2file(filepath, predictions)\n","!head -n 20 test.pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jUntF5T6Dx2w","colab_type":"text"},"source":["If we have the references of this split, we can also evaluate the performance of our system on it. First, we must add them to the dataset object:\n"]},{"cell_type":"code","metadata":{"id":"-pccriZWDyqr","colab_type":"code","colab":{}},"source":["dataset.setOutput('y_test.txt',\n","             'test',\n","             type='text',\n","             id='target_text',\n","             pad_on_batch=True,\n","             tokenization=tokenize_y,\n","             sample_weights=True,\n","             max_text_len=y_max_text_len,\n","             max_words=y_max_words)\n","keep_n_captions(dataset, repeat=1, n=1, set_names=['test'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"riPUDl-xD1WM","colab_type":"text"},"source":["Next, we call the evaluation system: the sacreBLEU package:\n"]},{"cell_type":"code","metadata":{"id":"rfLzm4QBD2oj","colab_type":"code","colab":{}},"source":["from keras_wrapper.extra.evaluation import select\n","metric = 'sacrebleu'\n","# Apply sampling\n","extra_vars = dict()\n","extra_vars['tokenize_f'] = eval('dataset.' + tokenize_x)\n","extra_vars['language'] = params['TRG_LAN']\n","extra_vars['test'] = dict()\n","extra_vars['test']['references'] = dataset.extra_variables['test']['target_text']\n","metrics = select[metric](pred_list=predictions,\n","                                          verbose=1,\n","                                          extra_vars=extra_vars,\n","                                          split='test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTujympHCA2h","colab_type":"code","colab":{}},"source":["wandb.log({'BLEU_4_TEST': metrics['Bleu_4']})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jtfESZgUH6g_","colab_type":"text"},"source":["And that's all!"]}]}